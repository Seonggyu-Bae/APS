# 23/08/10

#### DP(Dynamic Programming)

- 동적 계획(Dynamic Programming) 알고리즘은 그리디 알고리즘과 같이 **최적화 문제**를 해결하는 알고리즘이다.

- 동적 계획 알고리즘은 먼저 입력 크기가 작은 부분 문제들을 모두 해결한 후에 그 해들을 이용하여 보다 큰 크기의 부분 문제들을 해결하여, 최종적으로 원래 주어진 입력의 문제를 해결하는 알고리즘이다.

피보나치 수 DP 적용 알고리즘

- ```python
  def fibo2(n):
      f = [0] * (n+1)
      f[0] = 1
      f[1] = 2
      for i in range(2, n+1):
          f[i] = f[i-1] + f[i-2]
  
      return f[n]
  ```

- memoization을 재귀적 구조에 사용하는 것보다 반복적 구조로 DP를 구현한 것이 성능 면에서 보다 효율적이다.

- 재귀적 구조는 내부에 시스템 호출 스택을 사용하는 오버헤드가 발생하기 때문이다.

#### DFS(Depth First Search, 깊이 우선 탐색)

- 비선형구조인 그래프 구조는 그래프로 표현된 모든 자료를 빠짐없이 검색하는 것이 중요함.

- 두가지 방법
  
  - 깊이 우선 탐색(Depth First Search, DFS)
  
  - 너비 우선 탐색(Breadth First Search, BFS)

##### DFS란?

- 시작 정점의 한 방향으로 갈 수 있는 경로가 있는 곳까지 깊이 탐색해 가다가 더이상 갈 곳이 없게 되면, 가장 마지막에 만났던 갈림길 간선이 있는 정점으로 되돌아와서 다른 방향의 정점으로 탐색을 계속 반복하여 결국 모든 정점을 방문하는 순회방법

- 가장 마지막에 만났던 갈림길의 정점으로 되돌아가서 다시 깊이 우선 탐색을 반복해야 하므로 후입선출 구조의 스택 사용

##### DFS 알고리즘

1. 시작 정점 v를 결정하여 방문한다.

2. 정점 v에 인접한 정점 중에서
   
   1. 방문하지 않은 정점 w가 있으면, 정점 v를 스택에 push하고 정점 w를 방문한다. 그리고 w를 v로 하여 다시 2. 를 반복한다.
   
   2. 방문하지 않은 정점이 없으면, 탐색을 방향을 바꾸기 위해서 스택을 pop하여 받은 가장 마지막 방문 정점을 v로하여 다시 2.를 반복한다.

3. 스택이 공백이 될 때까지 2. 를 반복한다.

```python
visited[], stack[] 초기화

DFS(v)
    시작점 v 방문;
    while{
        if(v의 인접 정점 중 방문 안 한 정점 w가 있으면)
            push(v)
            v <- w; (w에 방문)
            visited[w] <- true;
        else
            if(스택이 비어 있지 않으면)
                v <- pop(stack);
            else
                break
    }
end DFS()
```

#### DFS 예

- 초기상태 : 배열 visited(정점의 개수만큼) 를 False로 초기화하고, 공백 스택을 생성
1. 첫번째 정점을 시작으로 깊이 우선 탐색을 시작 (visited[0]을 True로)

2. 

---

# 23/08/09

#### 스택(Stack)

- 물건을 쌓아 올리듯 자료를 쌓아 올린 형태의 자료구조이다.

- 스택에 저장된 자료는 선형 구조를 갖는다.
  
  - 선형구조 : 자료 간의 관계가 1대1의 관계를 갖는다.
  
  - 비선형구조 : 자료 간의 관계가 1대 N의 관계를 갖는다. (Ex. 트리)

- 스택에 자료를 삽입하거나 스택에서 자료를 꺼낼 수 있다.

- 마지막에 삽입한 자료를 가장 먼저 꺼낸다. **후입선출(LIFO : Last-In-First-Out)** 이라고 부른다.
  
  - 예를 들어 스택에 1, 2, 3순으로 자료를 삽입한 후 꺼내면 3, 2, 1 순으로 꺼낼 수 있다.

#### 스택을 프로그램에서 구현하기 위해서 필요한 자료구조와 연산

- **자료구조** : 자료를 선형으로 저장할 저장소
  
  - 배열을 사용할 수 있다.
  
  - 저장소 자체를 스택이라 부르기도 한다.
  
  - 스택에서 마지막 삽입된 원소의 위치를 top이라 부른다.

- **연산**
  
  - 삽입 : 저장소에 자료를 저장한다. 보통 push라고 부른다.
  
  - 삭제 : 저장소에서 자료를 꺼낸다. 꺼낸 자료는 삽입한 자료의 역순으로 꺼낸다. 보통 pop이라고 부른다.
  
  - 스택이 공백인지 아닌지를 확인하는 연산. isEmpty
  
  - 스택의 top에 있는 item(원소)를 반환하는 연산. peek

#### 스택의 push 알고리즘

- append 메소드를 통해 리스트의 마지막에 데이터를 삽입

- ```python
  def push(s, item):
      s.append(item)
  
  ################################
  def push(item, size):
   global top
   top += 1
   if top==size:
   print('overflow!')
   else:
   stack[top] = item
   size = 10
   stack [0] * size
   top = -1
  
  push(10, size)
   top += 1
   stack[top] = 20
  ```

#### 스택의 pop 알고리즘

```python
def pop():
  if len(s) == 0:
      #underflow
      return
  else:
      return s.pop()

######################################
def pop():
  global top
  if top == -1 : 
      print('underflow')
      return 0
  else:
      top -= 1
      return stack[top+1]

print(pop())

if top > -1:
  top -= 1
  print(stack[top+1])
```

#### 스택 구현 고려 사항

- 1차원 배열을 사용하여 구현할 경우 구현이 용이하다는 장점이 있지만 스택의 크기를 변경하기가 어렵다는 단점이 있다.

- 이를 해결하기 위한 방법으로 저장소를 동적으로 할당하여 스택을 구현하는 방법이 있다. 동적 연결리스트를 이용하여 구현하는 방법을 의미한다. 구현이 복잡하다는 단점이 있지만 메모리를 효율적으로 사용한다는 장점을 가진다.

#### 스택의 응용1 : 괄호검사

- 조건
  
  1. 왼쪽 괄호의 개수와 오른쪽 괄호의 개수가 같아야 한다.
  
  2. 같은 괄호에서 왼쪽 괄호는 오른쪽 괄호보다 먼저 나와야 한다.
  
  3. 괄호 사이에는 포함관계만 존재한다.

- 알고리즘 개요
  
  - 문자열에 있는 괄호를 차례대로 조사하면서 왼쪽 괄호를 만나면 스택에 삽입하고, 오른쪽 괄호를 만나면 스택에서 top 괄호를 삭제한 후 오른쪽 괄호와 짝이 맞는지를 검사한다.
  
  - 이 때, 스택이 비어 있으면 조건 1 또는 조건 2 에 위배되고 괄호의 짝이 맞지 않으면 조건 3에 위배된다.
  
  - 마지막 괄호까지를 조사한  후에도 스택에 괄호가 남아 있으면 조건 1에 위배된다.

#### 스택의 응용2 : function call

- 프로그램에서의 함수 호출과 복귀에 따른 수행 순서를 관리
  
  - 가장 마지막에 호출된 함수가 가장 먼저 실행을 완료하고 복귀하는 후입선출 구조이므로, 후입선출 구조의 스택을 이용하여 수행순서 관리
  
  - 함수 호출이 발생하면 호출한 함수 수행에 필요한 지역변수, 매개변수 및 수행 후 복귀할 주소 등의 정보를 스택 프레임(stack frame)에 저장하여 시스템 스택에 삽입
  
  - 함수의 실행이 끝나면 시스템 스택의 top 원소(stack frame)을 삭제(pop)하면서 프레임에 저장되어 있던 복귀주소를 확인하고 복귀
  
  - 함수 호출과 복귀에 따라 이 과정을 반복하여 전체 프로그램 수행이 종료되면 시스템 스택은 공백 스택이 된다.

#### 재귀호출

- 자기 자신을 호출하여 순환 수행되는 것

- 함수에서 실행해야 하는 작업의 특성에 따라 일반적인 호출방식보다 재귀호출방식을 사용하여 함수를 만들면 프로그램의 크기를줄이고 간단하게 작성가능
  
  - 예시 : factorial, 피보나치

- 0과 1로 시작하고 이전의 두 수 합을 다음 항으로 하는 수열을 피보나치라 한다
  
  - 0, 1, 1, 2, 3, 5, 8, 13, .....

- 피보나치 수열의 i번 째 값을 계산하는 함수 F를 정의 하면 다음과 같다.
  
  - F0 = 0, F1=1
  
  - Fi = Fi-1 + Fi-2 for i >= 2

- 위의 정의로부터 피보나치 수열의 i번째 항을 반환하는 함수를 재귀함수로 구현할 수 있다.

- ```python
  def fibo(n):
      if n < 2:
          return n
      else:
          return fibo(n-1) + fibo(n-2)
  ```

#### Memoization

- 앞의 예에서 피보나치 수를 구하는 함수를 재귀함수로 구현한 알고리즘은 문제점이 있다.

- 엄청난 중복 호출이 존재한다는 것이다.

- 메모이제이션(Memoization)은 컴퓨터 프로그램을 실행할 때 이전에 계산한 값을 메모리에 저장해서 매번 다시 계산하지 않도록 하여 전체적인 실행속도를 빠르게 하는 기술이다. 동적 계획법의 핵심이 되는 기술이다.

- 앞의 예에서 피보나치 수를 구하는 알고리즘에서 fibo(n)의 값을 계산하자마자 저장하면(memoize), 실행시간을 O(N)으로 줄일 수 있다.

- ```python
  def fibo1(n):
      global memo
      if n >= 2 and memo[n] == 0:
          memo[n] = (fibo1(n-1) + fibo1(n-2))
      return memo[n]
  ```
  
  memo = [0] * (n+1)
  memo[0] = 0
  memo[1] = 1

---

---

# 23/08/08

#### 문자열

#### 패턴 매칭

- 패턴 매칭에 사용되는 알고리즘
  
  - 고지식한 패턴 검색 알고리즘 (Brute Force)

- 카프-라빈 알고리즘

    KMP알고리즘
    
    
    - 보이어-무어 알고리즘
    
      ###### 고지식한 알고리즘(Brute Force)
    
      - 본문 문자열을 처음부터 끝까지 차례대로 순회하면서 패턴 내의 문자들을 일일이 비교하는 방식으로 동작
    
      ```python
      p = 'is'
      t = 'this is a book'
      M = len(p)
      N = len(t)
    
      # 같은 패턴을 찾았다면 그 패턴의 첫**번째 인덱스를 반환함
      # 아래 경우는 2를 반환함**
      # this is a book
      # 0123
      def BruteForce(p,t):
        i = 0
        j = 0
        while j < M and i <N:
            if t[i] != p[j]:
                i = i-j
                j = -1
            i = i + 1
            j = j + 1
        if j == M:
            return i-M
        else:
            return -1
    
    
      print(BruteForce(p,t))

- 시간복잡도
  
  - 최악의 경우 시간 복잡도는 텍스트의 모든 위치에서 패턴을 비교해야 하므로 O(MN)이 됨
  
  - 길이가 10000인 문자열에서 길이 80인 패턴을 찾는다고 할 때, 최악의 경우 약 10000 * 80  = 800,000 번의 비교가 일어남

##### KMP 알고리즘

- 불일치가 발생한 텍스트 스트링의 앞 부분에 어떤 문자가 있는지를 미리 알고 있으므로, 불일치가 발생한 앞 부분에 대하여 다시 비교하지 않고 매칭을 수행

- 패턴을 전처리하여 배열 next[M]을 구해서 잘못된 시작을 최소화함
  
  - next[M] : 불일치가 발생했을 경우 이동할 다음 위치

- 시간복잡도 : O(M+N)

##### 보이어-무어 알고리즘

- **오른쪽에서 왼쪽으로 비교**

- 대부분의 상용 소프트웨어에서 채택하고 있는 알고리즘

- 보이어-무어 알고리즘은 패턴에 오른쪽 끝에 있는 문자가 불일치 하고 이 문자가 패턴 내에 존재하지 않는 경우, 이동거리는 무려 패턴의 길이 만큼이 된다.

- 보이어-무어 알고리즘은 텍스트 문자를 다 보지 않아도 된다

- 발상의 전환 : 패턴의 오른쪽부터 비교한다

- 최악의 경우 수행시간 : O(MN)

- 입력에 따라 다르지만 일반적으로 O(N)보다 시간이 덜 든다

---

# 23/08/03

###### 부분집합 생성하기

- 각 원소가 부분집합에 포함되었는지를 loop를 이용하여 확인하고 부분집합을 생성하는 방법

- ```python
  bit = [0, 0, 0, 0]
  for i in range(2):
      bit[0] = i
      for j in range(2):
          bit[1] = j
          for k in range(2):
              bit[2] = k
              for l in range(2):
                  bit[3] = l
                  print_subset(bit)
  ```

- **비트 연산자**
  
  | &      | 비트 단위로 AND 연산을 한다           |
  |:------:|:---------------------------:|
  | **\|** | **비트 단위로 OR 연산을 한다**        |
  | **<<** | **피연산자의 비트 열을 왼쪽으로 이동시킨다**  |
  | **>>** | **피연산자의 비트 열을 오른쪽으로 이동시킨다** |

- **<< 연산자**
  
  - 1<<n  :  2^n 즉, 원소가 n개일 경우의 모든 부분집합의 수를 의미한다.

- **& 연산자**
  
  - i & (1<<j) : i의 j번째 비트가 1인지 아닌지를 검사한다.
  
  ```python
  arr = [3, 6, 7, 1, 5, 4]
  
  n = len(arr)
  
  for i in range(1<<n):    # 1<<n -> 부분 집합의 개수
      for j in range(n):    # 원소의 수 만큼 비트 비교
          if i & (1<<j):    # i의 j번 비트가 1인 경우
              print(arr[j], end=", ") # j번 원소 출력
  ```

##### 인덱스

- 인덱스

- ㄻ

- ㄻㄹ
  
  - ㄻㄹ

##### 선택 정렬(Selection Sort)

- 주어진 자료들 중 가장 작은 값의 원소부터 차례대로 선택하여 위치를 교환하는 방식
  
  - 앞서 살펴본 셀렉션 알고리즘을 전체 자료에 적용한 것이다

- 정렬 과정
  
  - 주어진 리스트 중에서 최소값을 찾는다.
  
  - 그 값을 리스트의 맨 앞에 위치한 값과 교환한다.
  
  - 맨 처음 위치를 제외한 나머지 리스트를 대상으로 위의 과정을 반복한다.

- 시간복잡도 : O(N^2)

##### 셀렉션 알고리즘(Selection Algorithm)

- 저장되어 있는 자료로부터 K번째로 큰 혹은 작은 원소를 찾는 방법
  
  - 최소값, 최대값 혹은 중간값을 찾는 알고리즘을 의미하기도 함

- 선택과정
  
  - 셀렉션은 아래와 같은 과정을 통해 이루어진다.
    
    - 정렬 알고리즘을 이용하여 자료 정렬
    
    - 원하는 순서에 있는 원소 가져오기

- K가 비교적 작을 때 유용하며 O(kn)의 수행시간을 필요로함

---

# 23/08/02

##### 2차원 배열

- 1차원 List를 묶어놓은 List

- 2차원 이상의 다차원 List는 차원에 따라 Index를 선언

- 2차원 List의 선언 : 세로길이(행의 개수), 가로길이(열의 개수)를 필요로 함

- Python에서는 데이터 초기화를 통해 변수선언과 초기화가 가능함

- arr = [[0,1,2,3],[4,5,6,7]] (2행 4열의 2차원 List)

##### 배열 순회

- N X M 배열의 N*M 개의 모든 원소를 빠짐없이 조사하는 방법
  
  **행 우선순회**

- ```python
  for i in range(n):
      for j in range(m):
          Array[i][j]
  ```

**열 우선순회**

- ```python
  for j in range(m):
      for i in range(n):
          Array[i][j]
  ```

**지그재그 순회**

- ```python
  for i in range(n):
      for j in range(m):
          Array[i][j + (m-1-2*j) * (i%2)]
  ```

#### 델타를 이용한 2차 배열 탐색

- **2차 배열의 한 좌표에서 4방향의 인접 배열 요소를 탐색하는 방법**

- ```python
  arr[][] #NXM
  
  di = [0, 1, 0, -1]
  dj = [1, 0, -1, 0]
  
  for i in range(N):
      for j in range(M):
          for k in range(4):
              ni = i + di[k]
              nj = j + dj[k]
              if 0 <= ni <= N and 0 <= nj <= N #is valid index?
                  Array[ni][nj]
  ```

```python
#전치행렬

arr = [[1,2,3], [4,5,6], [7,8,9]]
"""
123
456
789
"""

for i in range(3):
    for j in range(3):
        if i < j:
            arr[i][j], arr[j][i] = arr[j][i], arr[i][j]

print(arr) # [[1,4,7], [2,5,8], [3,6,9]
"""
147
258
369
"""
```

##### 검색(Search)

- 저장되어 있는 자료 중에서 원하는 항목을 찾는 작업

- 목적하는 탐색 키를 가진 항목을 찾는 것
  
  - 탐색 키( Search Key) : 자료를 구별하여 인식할 수 있는 키

- 검색의 종류
  
  - 순차 검색(Sequential Searach)
  
  - 이진 검색(Binary Search)
  
  - 해쉬 (Hash)

**순차 검색(Sequential Search)**

- 일렬로 되어 있는 자료를 순서대로 검색하는 방법
  
  - 가장 간단하고 직관적인 검색 방법
  
  - 배열이나 연결 리스트 등 순차구조로 구현된 자료구조에서 원하는 항목을 찾을 때 유용함
  
  - 알고리즘이 단순하여 구현이 쉽지만, 검색 대상의 수가 많은 경우에는 수행시간이 급격히 증가하여 비효율적임

- 2가지 경우
  
  - 정렬되어 있지 않은 경우
    
    - 첫번째 원소부터 순서대로 검색 대상과 키 값이 같은 원소가 있는지 비교하며 찾는다.
    
    - 키 값이 동일한 원소를 찾으면 그 원소의 인덱스를 반환한다.
    
    - 자료구조의 마지막에 이를 때 까지 검색 대상을 찾지 못하면 검색 실패
    
    - 찾고자 하는 원소의 순서에 따라 비교 회수가 결정됨
      
      - 첫번째 원소를 찾을 때는 1번 비교, 두번째 원소를 찾을 때는 2번 비교
    
    - 정렬되지 않은 자료에서의 순차 검색의 평균 비교 회수 = (1/n) * (1+2+3+ ... + n) = (n+1)/2
    
    - 시간 복잡도 : O(N)
  
  ```python
  def seqserch(a, n, key):
      i = 0
      while i<n and a[i]!= key:
          i = i+1
      if i<n:
          return i
      else:
          return -1
  ```
  
  - 정렬되어 있는 경우
    
    - 자료가 오름차순으로 정렬된 상태에서 검색을 실시한다고 가정
    
    - 자료를 순차적으로 검색하면서 키 값을 비료하여, 원소의 키 값이 검색 대상의 키 값보다 크면 찾는 원소가 없다는 것이므로 더 이상 검색하지 않고 검색종료
    
    - 찾고자 하는 원소의 순서에 따라 비교회수가 결정
      
      - 정렬이 되어있으므로, 검색 실패를 반환하는 경우 평균 비교회수가 반으로 줄어듬
      
      - 시간 복잡도 : O(N)
  
  ```python
  def seqserch2(a, n, key):
      i = 0
      while i < n and a[i] < key:
          i = i+1
      if i < n and a[i] == key:
          return i
      else:
          return -1
  ```

 

##### 이진 검색(Binary Search)

- 검색과정
  
  - 자료의 중앙에 있는 원소를 고른다.
  
  - 중앙 원소의 값과 찾고자 하는 목표 값을 비교
  
  - 목표 값이 중앙값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색 수행, 크다면 자료의 오른쪽 반에 대해서 새로 검색을 수행
  
  - 찾고자 하는 값을 찾을 때 까지 위 과정을 반복

- 구현
  
  - 검색 범위의 시작점과 종료점을 이용하여 검색을 반복 수행
  
  - 이진 검색의 경우, 자료에 삽입이나 삭제가 발생했을 때 배열의 상태를 항상 정렬 상태로 유지하는 추가 작업 필요

- ```python
  def binsearch(a, N, key):
      start = 0
      end = N-1
      while start <= end:
          middle = (start + end) //2
          if a[middle] == key:        # search !
              return true
          elif a[middle] > key:
              end = middle -1
          else:
              start = middle + 1
      return false                # search fail
  ```

```python
def binsearch2(a, low, high, key):
    if low > high: # search fail
        return false
    else:
        middle = (low + high) //2
        if key == a[middle]:        # search !
            return true
        elif key < a[middle]:
            return binsearch2(a, low, middle-1, key)
        elif key > a[middle]:
            return binsearch2(a, middle+1, high, key)
```

---

# 23/08/01

##### 카운팅 정렬(Countiong Sort)

- **항목들의 순서를 결정하기 위해 집합에 각 항목이 몇 개씩 있는지 세는 작업을 하여, 선형 시간에 정렬하는 효율적인 알고리즘**

- **제한사항**
  
  - 정수나 정수로 표현할 수 있는 자료에 대해서만 적용 가능 : 각 항목의 발생 회수를 기록하기 위해, 정수 항목으로 인덱스 되는 카운트들의 배열을 사용하기 때문이다.
  
  - 카운트들을 위한 충분한 공간을 할당하려면 집합 내의 가장 큰 정수를 알아야 한다.

- 시간 복잡도 O(n+K) : n은 리스트 길이, k는 정수의 최대값

##### 완전검색(Exaustive Search)

- 완전 검색 방법은 문제의 해법으로 생각할 수 있는 모든 경우의 수를 나열해보고 확인하는 기법이다.

- Brute-force 혹은 generate-and-test 기법이라고도 불린다.

- 모든 경우의 수를 테스트한 후, 최종 해법을 도출한다.

- 일반적으로 경우의 수가 상대적으로 작을 때 유용하다.

- 모든 경우의 수를 생성하고 테스트하기 때문에 수행 속도는 느리지만, 해답을 찾아내지 못할 확률이 작다.

##### 탐욕(Greedy) 알고리즘

- 탐욕 알고리즘은 최적해를 구하는 데 사용되는 근시안적인 방법

- 여러 경우 중 하나를 결정해야 할 때마다 그 순간에 최적이라고 생각되는 것을  선택해 나가는 방식으로 진행하여 최종적인 해답에 도달한다.

- 각 선택의 시점에서 이루어지는 결정은 지역적으로는 최적이지만, 그 선택들을 계속 수집하여 최종적인 해답을 만들었다고 하여, 그것이 최적이라는 보장은 없다.

- 일반적으로, 머릿속에 떠오르는 생각을 검증 없이 바로 구현하면 Greedy 접근이 된다.

###### 탐욕 알고리즘의 동작과정

1. 해 선택 : 현재 상태에서 부분 문제의 최적 해를 구한 뒤, 이를 부분해 집합(Solution Set)에 추가한다.

2. 실행 가능성 검사 : 새로운 부분해 집합이 실행 가능한지를 확인한다. 곧, 문제의 제약 조건을 위반하지 않는지를 검사한다.

3. 해 검사 : 새로운 부분해 집합이 문제의 해가 되는지를 확인한다. 아직 전체 문제의 해가 완성되지 않았다면 1)의 해 선택부터 다시 시작한다

---

# 23/07/31

APS(Algorithm Problem Solving)

##### APS 과정의 목표 중의 하나는 보다 좋은 알고리즘을 이해하고 활용하는 것이다.

###### 무엇이 좋은 알고리즘인가?

1. 정확성 :  얼마나 정확하게 동작하는가

2. 작업량 : 얼마나 적은 연산으로 원하는 결과를 얻어내는가

3. 메모리 사용량 : 얼마나 적은 메모리를 사용하는가

4. 단순성 : 얼마나 단순한가

5. 최적성 : 더 이상 개선할 여지 없이 최적화되었는가

###### 알고리즘의 작업량을 표현할 때 시간복잡도로 표현한다.

###### 시간 복잡도(Time Complexity)

- 실제 걸리는 시간을 측정

- 실행되는 명령문의 개수를 계산

###### 배열이란?

- 일정한 자료형의 변수들을 하나의 이름으로 열거하여 사용하는 자료구조

###### 배열의 필요성

- 프로그램 내에서 여러 개의 변수가 필요할 때, 일일이 다른 변수명을 이용하여 자료에 접근하는 것은 매우 비효율적일 수 있다.

- 배열을 사용하면 하나의 선언을 통해서 둘 이상의 변수를 선언할 수 있다.

- 단순히 다수의 변수 선언을 의미하는 것이 아니라, 다수의 변수로는 하기 힘든 작업을 배열을 활용해 쉽게 할 수 있다.

###### 정렬

- 2개 이상의 자료를 특정 기준에 의해 작은 값부터 큰 값(오름차순 :  ascending), 혹은 그 반대의 순서대로 (내림차순 : descending)  재배열하는 것

- 키
  
  - 자료를 정렬하는 기준이 되는 특정 값

###### 버블 정렬(Bubble Sort)

- 인접한 두 개의 원소를 비교하며 자리를 계속 교환하는 방식

- 정렬과정
  
  - 첫 번째 원소부터 인접한 원소끼리 계속 자리를 교환하면서 맨 마지막 자리까지 이동한다.
  
  - 한 단계가 끝나면 가장 큰 원소가 마지막 자리로 정렬된다.
  
  - 교환하며 자리를 이동하는 모습이 물 위에 올라오는 거품 모양과 같다고 하여 버블 정렬이라고 한다.

- 시간 복잡도 O(n^2)
